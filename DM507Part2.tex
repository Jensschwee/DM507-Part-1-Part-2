\documentclass{article}
\usepackage[utf8]{inputenc} %dansk tegnsæt
\usepackage[danish]{babel}  %Sætter dokumentet til dansk dvs at auto generat navne bliver danske
\usepackage{amsmath} %mat
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{bold-extra}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{color}
\usepackage{parskip}% http://ctan.org/pkg/parskip

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
\pagestyle{fancy}
\fancyhead[CO,CE]{Projekt del 2 - DM507 - jesph13 og jenss12}
\begin{document}
{\centering
\huge
Projekt del 2\\
Algoritmer og datastrukturer (DM507)\\
\large
\bigskip
Institut for Matematik og Datalogi Syddansk Universitet, Odense\\
\bigskip
20. Maj 2015\\
\bigskip
Af Jesper Wohlert Hansen \& Jens Hjort Schwee\\
}
\newpage

\section*{Introduktion}
Denne rapport dækker over en implementation af Huffman kodning, herunder operationer til enkodning og dekodning af filer. Rapportens hovedafsnit beskriver disse operationer, mens at et sidste afsnit er tilset tests.

\subsection*{Systemkrav \& kørsel}
Bemærk, for at køre programmerne er \textbf{Java 8} påkrævet, da der i programmerne benyttes stream\footnote{https://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html} bibliotekets funktionalitet.

\bigskip

De to Java programmer, \texttt{Encode} og \texttt{Decode}. Køres således:

\begin{verbatim}
    java Encode <input> <encoding>
\end{verbatim}

\begin{verbatim}
    java Decode <encoding> <output>
\end{verbatim}

\newpage

\section*{Opgave 1}
I denne opgave skal der konstrueres et program, som kan læse en input fil og producere et Huffman-kodet version af denne fil. For at gøre dette, laves der to gennemløb af input-filen.

\subsection*{Første gennemløb}

Inputfilen indlæses og der bliver allokeret et nyt array til at indeholde frekvenserne for de 256 forskellige karakterer som programmet godtager. Herefter læses filen bit for bit hvorved at der genereres bitstrenge af længde 8 (én byte). Denne byte kaldes for \texttt{readBits} og vil eksempelvis se således ud: \texttt{01001000}. \texttt{readBits} kan herefter parses til et heltal, som kan bruges som index i \texttt{frequencies} arrayet. Her lægges der 1 til frekvensen for at optælle frekvensen for hver byte, hvorefter alle frekvenserne skrives til output filen gennem \texttt{BitOutputStream}.

Til sidst i gennemløbet bygges der et Huffman træ med frekvenserne som input. \texttt{build} operationen er afdækket i det efterkommende afsnit (Huffman træet).
Returværdien fra \texttt{build} bruges til at lave Huffman kodningerne.

\begin{lstlisting}
// Encode.java
BitInputStream in = new BitInputStream(inFile);
BitOutputStream out = new BitOutputStream(outFile);

int bit;
int[] frequencies = new int[256];
String readBits = "";
String[] encodedTable;

while ((bit = in.readBit()) != -1) {
  readBits += "" + bit;
  if (readBits.length() % 8 == 0) {
    frequencies[Integer.parseInt(readBits, 2)] += 1;
    readBits = "";
  }
}

for (int i : frequencies) out.writeInt(i);

Element e = Huffman.build(frequencies);
encodedTable = Huffman.encode((DictBinTree.Node) e.data);
\end{lstlisting}

\newpage
\subsubsection*{Huffman træet}
Huffman træeerne bygges gennem metoden \texttt{Huffman.build}, som modtager et array med hyppigheder over de forskellige input.

Inde i metoden udregnes der hvor mange forskellige karakterer som optræder. Dette gemmes som \texttt{elementCount}, således vides der hvor mange blade, Huffman træet skal bestå af. Der indsættes elementer i en prioritetskø, disse elementer har en nøgle som er lig hyppigheden, og en værdi som er lig bladet. Bladende er repræsenteret ved \texttt{Node} fra del 1.

Til at begynde med fyldes køen med elementer af typen \texttt{Element} med hyppighed som nøgle og værdien er en \texttt{Node} objekt der indeholder karakterkoden. Herefter gennemgås køen ved at fjerne de to elementer med lavest hyppighed. Der laves en ny knude med disse to elementer som børn, dennes nøgle er summen af børnenes nøgler. Til sidst indsættes den nye knude som element i prioritetskøen. Når alle elementer er gennemgået vil det mindste element i køen indeholde roden for Huffmantræet.
\begin{lstlisting}
// Huffman.java
public static Element build(int[] table) {
  int elementCount = (int) IntStream.of(table)
    .filter(n -> n != 0)
    .count();
		
  if (elementCount > 0) {
    PQ pqHeap = new PQHeap(elementCount);
    IntStream.range(0, table.length)
      .filter(n -> table[n] != 0)
      .forEach(n -> pqHeap.insert(new Element(table[n], tree.new Node(n))));

    for (int i = 0; i < elementCount - 1; i++) {
      Element left = pqHeap.extractMin();
      Element right = pqHeap.extractMin();
	
      int key = left.key + right.key;

      DictBinTree.Node node = tree.new Node(key);
			
      node.left = (DictBinTree.Node) left.data;
      node.right = (DictBinTree.Node) right.data;
            
      pqHeap.insert(new Element(key, node));
    }
    return pqHeap.extractMin();
  }
  return null;
}
\end{lstlisting}
Huffman kodningen laves i \texttt{Huffman} klassen gennem metoden \texttt{encode}. Dette er en metode som kalder den rekursive version af sig selv indtil alle knuder er gennemløbet. Hertil skal bruges en tabel til at indeholde alle præfikskoder, hvilket er repræsenteret ved et \texttt{String} array som til start er tomt. Indekset i denne tabel er nøglen for knuden, altså karakteren. \texttt{recursiveEncode} konstruerer så en bitstreng rekursivt ved at lægge 0 til enden hvis den skal til venstre, eller 1 hvis den skal til højre. Når den ikke kan komme længere gemmes bitstrengen i tabellen.

\begin{lstlisting}
// Huffman.java
public static String[] encode(DictBinTree.Node root) {
  String[] table = new String[256];
  if(root.right != null || root.left != null)
    recursiveEncode(root, table, "");
  else
    recursiveEncode(root, table, "0");
  return table;
}
...
private static void recursiveEncode(DictBinTree.Node node, String[] table, String bitString) {
  if (node == null) return;
  if (node.left == null && node.right == null) {
    table[node.key] = bitString;
  } else {
    recursiveEncode(node.left, table, bitString + "0");
    recursiveEncode(node.right, table, bitString + "1");
  }
}
\end{lstlisting}

\subsection*{Andet gennemløb}
I andet gennemløb benyttes lignende kode fra første gennemløb til at genåbne inputfilen og læse bytesne. Forskellen er, at der i dette gennemløb skrives Huffmankodningen for hver karakter til outputfilen ved opslag i tabellen modtaget fra \texttt{Huffman.encode}.

\begin{lstlisting}
// Encode.java
while ((bit = in.readBit()) != -1) {
  readBits += "" + bit;
  if (readBits.length() % 8 == 0) {
    for (char c : encodedTable[Integer.parseInt(readBits, 2)].toCharArray())
      out.writeBit(Integer.parseInt(Character.toString(c)));
    readBits = "";
  }
}
\end{lstlisting}

Dette resulterer i en output fil som indeholder 256 ints, der repræsenterer hyppigheden for hver byte, samt huffmankodningen til slut i filen.

\section*{Opgave 2}
Formålet med denne delopgave er at reetablere det originale indhold, altså dekomprimering, af en Huffmankodet fil. Dette er gjort igennem programmet \texttt{Decode}.

\begin{lstlisting}
//Huffman.java
public static Map<String, Integer> decode(DictBinTree.Node root) {
  Map<String, Integer> table = new HashMap<String, Integer>();
  if(root.right != null || root.left != null)
    recursiveDecode(root, table, "");
  else
    recursiveDecode(root, table, "0");
  return table;
}

private static void recursiveDecode(DictBinTree.Node node, 
Map<String, Integer> table, String bitString){
  if (node == null) return;
  if (node.left == null && node.right == null)
    table.put(bitString, node.key);
  else {
    recursiveDecode(node.left, table, bitString + "0");
    recursiveDecode(node.right, table, bitString + "1");
  }
}
\end{lstlisting}

Det første der sker i programmet er at der læses de 256 integers (hyppigheder), som ligger først i filen. Disse bliver brugt til at bygge Huffman træet. Integersne bliver gemt i et array og Huffmantræet bygges via \texttt{Huffman.build}. Ved at benytte den samme algoritme til at bygge Huffman træet i både \texttt{Encode} og \texttt{Decode} sikrer vi, at filen bliver dekomprimeret korrekt ift. enkodningen. 
For at kunne oversætte tilbage til udgangspunktet skal der vides hvilke præfikskoder der er blevet brugt. Disse findes ved at kalde: \texttt{Huffman.decode(Node)}

Metoden \texttt{decode} bruges til at få et HashMap med alle præfikskoderne. Der er valgt at benytte et HashMap med en \texttt{String} som nøglen og \texttt{Integer} som værdi, da der hver gang der bliver læst en bit i filen skal tjekkes hvorhvidt dette er en præfikskode.
Før der kaldes \texttt{recursiveDecode}, sikrers der at der ikke kun er en enkelt knude i træet. Dette gøres for at koden også virker ved input med kun ét tegn.

Kaldet til \texttt{recursiveDecode} fra \texttt{decode}, består af følgende: 
\begin{enumerate}
    \item Startstedet for koden
    \item Hvilket map koden skal indsættes i
    \item Hvad præfikskoden skal starte med
\end{enumerate}

Metoden \texttt{recursiveDecode} er bygget op omkring rekursive kald. Hvis knuden den får ind ikke er \texttt{null}, og ikke har nogle børn, så er det en præfikskode med nøglen som værdi. Hvis den derimod har børn, vides det, at dette ikke er en af præfikskoderne. Derfor kaldes \texttt{recursiveDecode}, med både højre og venstre barn, og præfikskoden ændres herefter.
Når \texttt{recursiveDecode} er kørt færdig, er alle knuder blevet ramt og alle præfikskoder er indsat i HashMappet.
\begin{lstlisting}
//Decode.java
FileInputStream inFile = new FileInputStream(args[0]);
FileOutputStream outFile = new FileOutputStream(args[1]);

BitInputStream in = new BitInputStream(inFile);
BitOutputStream out = new BitOutputStream(outFile);
...
Map<String, Integer> decodeTable = Huffman.decode((DictBinTree.Node)e.data);
String readBits = "";
int bit;
int writeCount = e.key;
while ((bit = in.readBit()) != -1) {
  readBits += "" + bit;
  Integer decode = decodeTable.get(readBits);
  if (decode != null) {
    String bitstring = Integer.toBinaryString(decode);
    for (int i = bitstring.length() - 8; i < 0; i++) 
      out.writeBit(0);	

    for (char c : bitstring.toCharArray())
      out.writeBit(Integer.parseInt(Character.toString(c)));

    readBits = "";
    writeCount--;
    if (writeCount < 1) 
      break;
  }
}
...
\end{lstlisting}
For at vide hvor mange elementer der skal til output læses træets rods værdi. Efter hver skrivning reduceres denne med et, indtil alle karakterer er skrevet til filen.
Programmet fortsætter med at læse input filen, bit for bit. Hver gang der er læst en bit lægges det til \texttt{readBits} som indeholder op til de sidste 8 bit der er læst.
Der søges i mappet om, \texttt{readBit} er en præfikskode, hvis den ikke er, så læs næste bit uden for foretage yderligere. Hvis vi derimod har fat i en præfikskode, så skal der skrives til output filen.
For at få det rigtige skrevet i filen skal der sikrers at det som der skal skrives er 8 bits, hvis det ikke er tilfældet skrives der nogle padding bits med "0" først. Når formatet er på plads skrives resten af de bits som repræsenterer den binære værdi. Hvis alle elementer er udskrevet, stoppes udskrivningen. Herved fjernes evt. padding bits fra den endelige fil.
\newpage
\section*{Test}
Begge programmer er testet på måde som er beskrevet i oplægget, som også kan læses i introduktionen.
\subsection*{Encode test}
Encode er testet med forskellige filer som input, herunder billeder, tekst, og tomme dokumenter.
For simple input er Huffman træet der er blevet lavet, set i debuggeren, og tegnet i hånden, for at sikker korrektheden heraf.
\subsection*{Decode test}
Decode er testet enkodede filer, tomme inputs samt ikke enkodede filer.
Yderligere er der verifiseret input og output ved at se på endelige filer som har været igemmen både Encode og Decode.

\end{document}
